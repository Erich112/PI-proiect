{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm98VKkMH2gc"
      },
      "source": [
        "Initializare model + date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuI95CBC6EXJ",
        "outputId": "4f1ef567-0280-479b-a4e4-ed412b776cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.1.0-py3-none-any.whl (699 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.2/699.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Collecting hub-sdk>=0.0.2 (from ultralytics)\n",
            "  Downloading hub_sdk-0.0.2-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: hub-sdk, thop, ultralytics\n",
            "Successfully installed hub-sdk-0.0.2 thop-0.1.1.post2209072238 ultralytics-8.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install the ultralytics package from PyPI\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "D01YpYzGIEHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa3f089d-815c-4b99-9be5-6c43d726c0f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "detZar = '/content/drive/My Drive/IMG-20231117-WA0000.jpg'\n",
        "detMob = '/content/drive/My Drive/index-luxuryfurniture-1659361945.png'\n",
        "detMark = '/content/drive/My Drive/20231205_191020.jpg'\n",
        "detFin = '/content/drive/My Drive/testfin.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L6KGN3zw5iy-"
      },
      "outputs": [],
      "source": [
        "project = '/content/drive/My Drive/dataset-custom-1/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QSxlXclB6dus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5d517f-ce67-4bee-c885-09f0e4ca278c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 77.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a COCO-pretrained YOLOv8n model\n",
        "model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aVsMPfz26Lq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7d895e-21c0-4dc8-ff0d-1901f36e4949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.0 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/drive/My Drive/dataset-custom-1/data.yaml, epochs=20, time=None, patience=50, batch=16, imgsz=1024, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 16.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=38\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    758722  ultralytics.nn.modules.head.Detect           [38, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3018258 parameters, 3018242 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/My Drive/dataset-custom-1/train/labels... 1758 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1758/1758 [07:28<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/My Drive/dataset-custom-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/dataset-custom-1/valid/labels... 263 images, 0 backgrounds, 0 corrupt: 100%|██████████| 263/263 [01:02<00:00,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/My Drive/dataset-custom-1/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000238, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/20      7.97G       1.17      4.122      1.174        290       1024: 100%|██████████| 110/110 [01:54<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:08<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156     0.0593      0.555     0.0761     0.0379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20      7.14G     0.8645      2.706      1.034        328       1024: 100%|██████████| 110/110 [01:45<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:08<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.438      0.245      0.197     0.0943\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20      8.89G     0.8247      1.993      1.035        454       1024: 100%|██████████| 110/110 [01:46<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:07<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.294      0.397      0.278      0.145\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20      7.66G     0.8056      1.614      1.016        205       1024: 100%|██████████| 110/110 [01:48<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:06<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.326       0.41      0.348      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20      8.66G     0.7798      1.379       1.01        290       1024: 100%|██████████| 110/110 [01:48<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:06<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.407      0.451      0.436      0.231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20      7.38G     0.7612       1.23     0.9989        251       1024: 100%|██████████| 110/110 [01:45<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:07<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156       0.51      0.497      0.511      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20      7.23G     0.7454      1.108     0.9797        415       1024: 100%|██████████| 110/110 [01:45<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:08<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.518      0.482      0.482      0.263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20      7.19G      0.738      1.028     0.9804        266       1024: 100%|██████████| 110/110 [01:46<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:07<00:00,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.582      0.469      0.535      0.276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20      7.68G     0.7384     0.9683     0.9748        350       1024: 100%|██████████| 110/110 [01:47<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:06<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.532      0.497      0.523      0.283\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20      7.83G     0.7235     0.9298     0.9673        149       1024: 100%|██████████| 110/110 [01:48<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:06<00:00,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.602      0.565       0.61      0.333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20      5.93G     0.7084     0.8141     0.9633        176       1024: 100%|██████████| 110/110 [01:46<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:06<00:00,  1.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.596      0.592       0.62      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20      5.69G     0.6939     0.7579     0.9566        261       1024: 100%|██████████| 110/110 [01:39<00:00,  1.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:07<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.617      0.575      0.628      0.353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20      5.72G     0.6848      0.731     0.9483        170       1024: 100%|██████████| 110/110 [01:39<00:00,  1.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:08<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.617      0.567      0.604      0.332\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20      5.72G     0.6796     0.6971     0.9398        221       1024: 100%|██████████| 110/110 [01:39<00:00,  1.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:06<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.651      0.567       0.62      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20      5.56G     0.6674     0.6785     0.9354        221       1024: 100%|██████████| 110/110 [01:40<00:00,  1.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:07<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.704       0.56      0.638      0.369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20      5.73G     0.6582     0.6651     0.9285        236       1024: 100%|██████████| 110/110 [01:40<00:00,  1.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:09<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.696      0.593      0.647       0.38\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20      5.73G     0.6558     0.6615     0.9269        214       1024: 100%|██████████| 110/110 [01:40<00:00,  1.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:07<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.654      0.623      0.669      0.377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20      5.52G     0.6481     0.6499     0.9205        228       1024: 100%|██████████| 110/110 [01:40<00:00,  1.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:06<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.651      0.653      0.667      0.384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20      6.01G     0.6409     0.6406     0.9183        154       1024: 100%|██████████| 110/110 [01:40<00:00,  1.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:08<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.652       0.63       0.66      0.385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20      5.53G     0.6349     0.6249     0.9116        257       1024: 100%|██████████| 110/110 [01:39<00:00,  1.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:09<00:00,  1.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156       0.71      0.587      0.657       0.38\n",
            "\n",
            "20 epochs completed in 0.632 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.0 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3013058 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 9/9 [00:12<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        263       1156      0.647      0.631      0.659      0.384\n",
            "                     a        263         74      0.817      0.608      0.762      0.383\n",
            "                     b        263         19      0.853      0.526      0.666        0.4\n",
            "                     c        263         20      0.263        0.8      0.633      0.351\n",
            "                     d        263         21      0.874      0.476      0.725       0.39\n",
            "                     e        263         98      0.955      0.437      0.775      0.426\n",
            "                     f        263         16      0.483       0.25       0.32      0.198\n",
            "                     g        263         28      0.322      0.786      0.486      0.266\n",
            "                     h        263         51      0.919      0.668      0.809      0.475\n",
            "                     i        263         61      0.781      0.821      0.891      0.391\n",
            "                     j        263          5      0.111        0.8      0.417      0.137\n",
            "                     k        263         11      0.623      0.603      0.495      0.302\n",
            "                     l        263         49      0.851      0.633      0.793       0.44\n",
            "                     m        263         10      0.447        0.2      0.249      0.139\n",
            "                     n        263         56      0.706       0.75       0.73       0.41\n",
            "                     o        263         83      0.817      0.867      0.906      0.436\n",
            "                     p        263         16          1      0.345      0.584      0.329\n",
            "                     q        263          7          0          0          0          0\n",
            "                     r        263         50      0.507      0.576      0.601      0.315\n",
            "                     s        263         59      0.533       0.78      0.688      0.327\n",
            "                     t        263         78      0.846      0.707      0.872      0.474\n",
            "                     u        263         36       0.44          1      0.839      0.463\n",
            "                     v        263         17      0.441      0.557      0.494      0.208\n",
            "                     w        263         22      0.808      0.384      0.534      0.325\n",
            "                     x        263         16      0.803      0.688      0.744       0.46\n",
            "                     y        263         36      0.538      0.694      0.661      0.292\n",
            "                     z        263         14      0.239      0.225      0.271      0.196\n",
            "                 black        263         38      0.981          1      0.995      0.851\n",
            "                  blue        263          4      0.835          1      0.995      0.933\n",
            "                  Sofa        263         23      0.815      0.955      0.957       0.65\n",
            "                 Table        263        138      0.797      0.783      0.887      0.558\n",
            "Speed: 0.8ms preprocess, 6.3ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Train the model on the COCO8 example dataset for 20 epochs\n",
        "results = model.train(data='/content/drive/My Drive/dataset-custom-1/data.yaml', epochs=20, imgsz=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnBfzw-I0aLD"
      },
      "source": [
        "1. Detectia unor zaruri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gYtsJwCi7X8Y"
      },
      "outputs": [],
      "source": [
        "model = YOLO('/content/runs/detect/train/weights/best.pt')\n",
        "# Validate the model\n",
        "from PIL import Image\n",
        "import cv2\n",
        "# infer on a local images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model(detZar)              # run prediction on img\n",
        "for result in results:\n",
        "    print(result.boxes)\n",
        "    im = cv2.imread(detZar)  # RGB PIL image\n",
        "    im_array = result.plot()  # plot a BGR numpy array of predictions\n",
        "    boxes = result.boxes.cpu().numpy()\n",
        "    xyxys = boxes.xyxy                       # get boxes on cpu in numpy\n",
        "    for box in boxes:\n",
        "      c = box.cls\n",
        "      cv2.putText(im, model.names[int(c)], (int(box.xyxy[0][0]), int(box.xyxy[0][1]-10)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
        "      cv2.rectangle(im, (int(box.xyxy[0][0]), int(box.xyxy[0][1])), (int(box.xyxy[0][2]), int(box.xyxy[0][3])), (0, 255, 0), 2)   # draw boxes on img\n",
        "      cv2.imwrite(\"Zarresults.jpg\",im)"
      ],
      "metadata": {
        "id": "qLc5gy5WUeBg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "dd6507f9-1bed-4b41-8d55-621962548d61"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "/content/drive/My Drive/IMG-20231117-WA0000.jpg does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-942d09011479>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetZar\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m# run prediction on img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;34m\"\"\"Calls the predict() method with given arguments to perform object detection.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for thread-safe inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;31m# Check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         )\n\u001b[0;32m--> 228\u001b[0;31m         self.dataset = load_inference_source(\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, imgsz, vid_stride, buffer)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadPilAndNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Attach source types to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, imgsz, vid_stride)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# files (relative to *.txt file parent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mIMG_FORMATS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: /content/drive/My Drive/IMG-20231117-WA0000.jpg does not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOZR_GluvlVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf270b8-7a05-435b-b234-2dacc2b2a36f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/My Drive/20231205_191020.jpg: 768x1024 1 black, 1 blue, 12.3ms\n",
            "Speed: 6.5ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 768, 1024)\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([34., 33.], device='cuda:0')\n",
            "conf: tensor([0.8351, 0.7894], device='cuda:0')\n",
            "data: tensor([[5.4885e+02, 1.4659e+03, 3.4056e+03, 2.5163e+03, 8.3512e-01, 3.4000e+01],\n",
            "        [7.1266e+02, 2.9374e+02, 3.6579e+03, 1.5155e+03, 7.8936e-01, 3.3000e+01]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (3096, 4128)\n",
            "shape: torch.Size([2, 6])\n",
            "xywh: tensor([[1977.2021, 1991.0818, 2856.7041, 1050.4591],\n",
            "        [2185.2654,  904.5944, 2945.2017, 1221.7148]], device='cuda:0')\n",
            "xywhn: tensor([[0.4790, 0.6431, 0.6920, 0.3393],\n",
            "        [0.5294, 0.2922, 0.7135, 0.3946]], device='cuda:0')\n",
            "xyxy: tensor([[ 548.8501, 1465.8522, 3405.5542, 2516.3113],\n",
            "        [ 712.6647,  293.7369, 3657.8662, 1515.4518]], device='cuda:0')\n",
            "xyxyn: tensor([[0.1330, 0.4735, 0.8250, 0.8128],\n",
            "        [0.1726, 0.0949, 0.8861, 0.4895]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "results = model(detMark)              # run prediction on img\n",
        "for result in results:\n",
        "    print(result.boxes)\n",
        "    im = cv2.imread(detMark)  # RGB PIL image\n",
        "    im_array = result.plot()  # plot a BGR numpy array of predictions\n",
        "    boxes = result.boxes.cpu().numpy()\n",
        "    xyxys = boxes.xyxy                       # get boxes on cpu in numpy\n",
        "    for box in boxes:\n",
        "      c = box.cls\n",
        "      cv2.putText(im, model.names[int(c)], (int(box.xyxy[0][0]), int(box.xyxy[0][1]-10)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
        "      cv2.rectangle(im, (int(box.xyxy[0][0]), int(box.xyxy[0][1])), (int(box.xyxy[0][2]), int(box.xyxy[0][3])), (0, 255, 0), 2)   # draw boxes on img\n",
        "      cv2.imwrite(\"Markresults.jpg\",im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycTBpRZgL83t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0bc545-0e0d-48c0-9f26-765b004b00b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/My Drive/index-luxuryfurniture-1659361945.png: 512x1024 1 Sofa, 11.9ms\n",
            "Speed: 4.2ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 1024)\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([36.], device='cuda:0')\n",
            "conf: tensor([0.6404], device='cuda:0')\n",
            "data: tensor([[2.1925e+03, 6.6855e+02, 3.9279e+03, 2.0000e+03, 6.4038e-01, 3.6000e+01]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (2000, 4000)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[3060.1533, 1334.2759, 1735.4048, 1331.4482]], device='cuda:0')\n",
            "xywhn: tensor([[0.7650, 0.6671, 0.4339, 0.6657]], device='cuda:0')\n",
            "xyxy: tensor([[2192.4509,  668.5518, 3927.8557, 2000.0000]], device='cuda:0')\n",
            "xyxyn: tensor([[0.5481, 0.3343, 0.9820, 1.0000]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "results = model(detMob)              # run prediction on img\n",
        "for result in results:\n",
        "    print(result.boxes)\n",
        "    im = cv2.imread(detMob)  # RGB PIL image\n",
        "    im_array = result.plot()  # plot a BGR numpy array of predictions\n",
        "    boxes = result.boxes.cpu().numpy()\n",
        "    xyxys = boxes.xyxy                       # get boxes on cpu in numpy\n",
        "    for box in boxes:\n",
        "      c = box.cls\n",
        "      cv2.putText(im, model.names[int(c)], (int(box.xyxy[0][0]), int(box.xyxy[0][1]-10)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
        "      cv2.rectangle(im, (int(box.xyxy[0][0]), int(box.xyxy[0][1])), (int(box.xyxy[0][2]), int(box.xyxy[0][3])), (0, 255, 0), 2)   # draw boxes on img\n",
        "      cv2.imwrite(\"Mobresults.jpg\",im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_M-at6St_b1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ad85b2-cb9c-4ff1-a8e4-3f3e8b47a5be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/My Drive/testfin.png: 768x1024 1 c, 4 es, 1 g, 1 l, 2 ns, 2 os, 1 p, 3 rs, 2 ss, 1 v, 1 w, 1 y, 1 black, 1 Sofa, 12.0ms\n",
            "Speed: 4.1ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 768, 1024)\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([ 5.,  3., 28., 18.,  5., 31., 19., 17., 23., 36., 22., 23., 17., 15.,  8., 22., 22.,  5., 33., 18., 27.,  5.], device='cuda:0')\n",
            "conf: tensor([0.9756, 0.9169, 0.9139, 0.9109, 0.9090, 0.9055, 0.8761, 0.8674, 0.8618, 0.8298, 0.7115, 0.6643, 0.6607, 0.6106, 0.5286, 0.5018, 0.4393, 0.3828, 0.3616, 0.3446, 0.2964, 0.2615], device='cuda:0')\n",
            "data: tensor([[1.1945e+02, 4.0747e+02, 1.4638e+02, 4.3080e+02, 9.7558e-01, 5.0000e+00],\n",
            "        [1.3366e+02, 3.5126e+02, 1.5704e+02, 3.6940e+02, 9.1692e-01, 3.0000e+00],\n",
            "        [8.0970e+01, 3.8527e+02, 1.0586e+02, 4.0757e+02, 9.1387e-01, 2.8000e+01],\n",
            "        [1.7818e+02, 3.9305e+02, 2.0512e+02, 4.1575e+02, 9.1095e-01, 1.8000e+01],\n",
            "        [1.5326e+02, 3.2505e+02, 1.7697e+02, 3.4177e+02, 9.0899e-01, 5.0000e+00],\n",
            "        [7.6583e+01, 3.6054e+02, 1.0131e+02, 3.8078e+02, 9.0546e-01, 3.1000e+01],\n",
            "        [1.0527e+02, 3.5459e+02, 1.2828e+02, 3.7447e+02, 8.7613e-01, 1.9000e+01],\n",
            "        [1.6887e+02, 3.6819e+02, 1.9480e+02, 3.8849e+02, 8.6736e-01, 1.7000e+01],\n",
            "        [1.4028e+02, 3.7438e+02, 1.6623e+02, 3.9544e+02, 8.6182e-01, 2.3000e+01],\n",
            "        [2.1806e+02, 1.9358e+02, 6.1199e+02, 3.7826e+02, 8.2976e-01, 3.6000e+01],\n",
            "        [1.2794e+02, 3.3017e+02, 1.4987e+02, 3.4743e+02, 7.1149e-01, 2.2000e+01],\n",
            "        [1.6104e+02, 3.4571e+02, 1.8565e+02, 3.6376e+02, 6.6428e-01, 2.3000e+01],\n",
            "        [1.1154e+02, 3.7948e+02, 1.3679e+02, 4.0119e+02, 6.6072e-01, 1.7000e+01],\n",
            "        [8.7273e+01, 4.1200e+02, 1.1369e+02, 4.3665e+02, 6.1059e-01, 1.5000e+01],\n",
            "        [1.4943e+02, 3.9913e+02, 1.7594e+02, 4.2275e+02, 5.2857e-01, 8.0000e+00],\n",
            "        [7.3161e+01, 3.3967e+02, 9.5972e+01, 3.5715e+02, 5.0180e-01, 2.2000e+01],\n",
            "        [1.0057e+02, 3.3363e+02, 1.2276e+02, 3.5089e+02, 4.3927e-01, 2.2000e+01],\n",
            "        [1.2799e+02, 3.2994e+02, 1.4994e+02, 3.4766e+02, 3.8282e-01, 5.0000e+00],\n",
            "        [2.2519e+02, 3.3819e+02, 4.4220e+02, 4.6500e+02, 3.6159e-01, 3.3000e+01],\n",
            "        [1.3347e+02, 3.5111e+02, 1.5713e+02, 3.6993e+02, 3.4456e-01, 1.8000e+01],\n",
            "        [1.1115e+02, 3.7949e+02, 1.3693e+02, 4.0108e+02, 2.9636e-01, 2.7000e+01],\n",
            "        [1.0087e+02, 3.3369e+02, 1.2290e+02, 3.5075e+02, 2.6153e-01, 5.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (465, 620)\n",
            "shape: torch.Size([22, 6])\n",
            "xywh: tensor([[132.9158, 419.1344,  26.9361,  23.3279],\n",
            "        [145.3494, 360.3313,  23.3754,  18.1416],\n",
            "        [ 93.4156, 396.4166,  24.8906,  22.2990],\n",
            "        [191.6514, 404.4000,  26.9376,  22.6938],\n",
            "        [165.1180, 333.4129,  23.7138,  16.7217],\n",
            "        [ 88.9445, 370.6603,  24.7234,  20.2344],\n",
            "        [116.7735, 364.5303,  23.0163,  19.8804],\n",
            "        [181.8351, 378.3402,  25.9226,  20.2971],\n",
            "        [153.2530, 384.9099,  25.9450,  21.0692],\n",
            "        [415.0263, 285.9200, 393.9308, 184.6763],\n",
            "        [138.9035, 338.8015,  21.9236,  17.2625],\n",
            "        [173.3453, 354.7319,  24.6113,  18.0468],\n",
            "        [124.1679, 390.3359,  25.2542,  21.7048],\n",
            "        [100.4807, 424.3251,  26.4145,  24.6434],\n",
            "        [162.6870, 410.9378,  26.5099,  23.6201],\n",
            "        [ 84.5663, 348.4073,  22.8107,  17.4839],\n",
            "        [111.6638, 342.2578,  22.1863,  17.2579],\n",
            "        [138.9654, 338.7979,  21.9536,  17.7150],\n",
            "        [333.6992, 401.5949, 217.0085, 126.8102],\n",
            "        [145.3024, 360.5180,  23.6593,  18.8163],\n",
            "        [124.0364, 390.2841,  25.7804,  21.5970],\n",
            "        [111.8887, 342.2189,  22.0302,  17.0578]], device='cuda:0')\n",
            "xywhn: tensor([[0.2144, 0.9014, 0.0434, 0.0502],\n",
            "        [0.2344, 0.7749, 0.0377, 0.0390],\n",
            "        [0.1507, 0.8525, 0.0401, 0.0480],\n",
            "        [0.3091, 0.8697, 0.0434, 0.0488],\n",
            "        [0.2663, 0.7170, 0.0382, 0.0360],\n",
            "        [0.1435, 0.7971, 0.0399, 0.0435],\n",
            "        [0.1883, 0.7839, 0.0371, 0.0428],\n",
            "        [0.2933, 0.8136, 0.0418, 0.0436],\n",
            "        [0.2472, 0.8278, 0.0418, 0.0453],\n",
            "        [0.6694, 0.6149, 0.6354, 0.3972],\n",
            "        [0.2240, 0.7286, 0.0354, 0.0371],\n",
            "        [0.2796, 0.7629, 0.0397, 0.0388],\n",
            "        [0.2003, 0.8394, 0.0407, 0.0467],\n",
            "        [0.1621, 0.9125, 0.0426, 0.0530],\n",
            "        [0.2624, 0.8837, 0.0428, 0.0508],\n",
            "        [0.1364, 0.7493, 0.0368, 0.0376],\n",
            "        [0.1801, 0.7360, 0.0358, 0.0371],\n",
            "        [0.2241, 0.7286, 0.0354, 0.0381],\n",
            "        [0.5382, 0.8636, 0.3500, 0.2727],\n",
            "        [0.2344, 0.7753, 0.0382, 0.0405],\n",
            "        [0.2001, 0.8393, 0.0416, 0.0464],\n",
            "        [0.1805, 0.7360, 0.0355, 0.0367]], device='cuda:0')\n",
            "xyxy: tensor([[119.4478, 407.4704, 146.3839, 430.7983],\n",
            "        [133.6617, 351.2605, 157.0371, 369.4021],\n",
            "        [ 80.9703, 385.2670, 105.8609, 407.5661],\n",
            "        [178.1826, 393.0531, 205.1201, 415.7469],\n",
            "        [153.2611, 325.0520, 176.9750, 341.7737],\n",
            "        [ 76.5827, 360.5431, 101.3062, 380.7775],\n",
            "        [105.2653, 354.5901, 128.2817, 374.4705],\n",
            "        [168.8738, 368.1917, 194.7964, 388.4888],\n",
            "        [140.2805, 374.3752, 166.2254, 395.4445],\n",
            "        [218.0609, 193.5818, 611.9917, 378.2581],\n",
            "        [127.9417, 330.1702, 149.8653, 347.4327],\n",
            "        [161.0396, 345.7085, 185.6509, 363.7553],\n",
            "        [111.5408, 379.4835, 136.7950, 401.1883],\n",
            "        [ 87.2735, 412.0034, 113.6879, 436.6468],\n",
            "        [149.4321, 399.1278, 175.9420, 422.7479],\n",
            "        [ 73.1609, 339.6654,  95.9717, 357.1493],\n",
            "        [100.5707, 333.6288, 122.7569, 350.8867],\n",
            "        [127.9886, 329.9403, 149.9422, 347.6553],\n",
            "        [225.1949, 338.1898, 442.2034, 465.0000],\n",
            "        [133.4727, 351.1098, 157.1320, 369.9261],\n",
            "        [111.1462, 379.4856, 136.9266, 401.0826],\n",
            "        [100.8736, 333.6900, 122.9037, 350.7478]], device='cuda:0')\n",
            "xyxyn: tensor([[0.1927, 0.8763, 0.2361, 0.9264],\n",
            "        [0.2156, 0.7554, 0.2533, 0.7944],\n",
            "        [0.1306, 0.8285, 0.1707, 0.8765],\n",
            "        [0.2874, 0.8453, 0.3308, 0.8941],\n",
            "        [0.2472, 0.6990, 0.2854, 0.7350],\n",
            "        [0.1235, 0.7754, 0.1634, 0.8189],\n",
            "        [0.1698, 0.7626, 0.2069, 0.8053],\n",
            "        [0.2724, 0.7918, 0.3142, 0.8355],\n",
            "        [0.2263, 0.8051, 0.2681, 0.8504],\n",
            "        [0.3517, 0.4163, 0.9871, 0.8135],\n",
            "        [0.2064, 0.7100, 0.2417, 0.7472],\n",
            "        [0.2597, 0.7435, 0.2994, 0.7823],\n",
            "        [0.1799, 0.8161, 0.2206, 0.8628],\n",
            "        [0.1408, 0.8860, 0.1834, 0.9390],\n",
            "        [0.2410, 0.8583, 0.2838, 0.9091],\n",
            "        [0.1180, 0.7305, 0.1548, 0.7681],\n",
            "        [0.1622, 0.7175, 0.1980, 0.7546],\n",
            "        [0.2064, 0.7095, 0.2418, 0.7476],\n",
            "        [0.3632, 0.7273, 0.7132, 1.0000],\n",
            "        [0.2153, 0.7551, 0.2534, 0.7955],\n",
            "        [0.1793, 0.8161, 0.2208, 0.8625],\n",
            "        [0.1627, 0.7176, 0.1982, 0.7543]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "results = model(detFin)              # run prediction on img\n",
        "for result in results:\n",
        "    print(result.boxes)\n",
        "    im = cv2.imread(detFin)  # RGB PIL image\n",
        "    im_array = result.plot()  # plot a BGR numpy array of predictions\n",
        "    boxes = result.boxes.cpu().numpy()\n",
        "    xyxys = boxes.xyxy                       # get boxes on cpu in numpy\n",
        "    for box in boxes:\n",
        "      c = box.cls\n",
        "      cv2.putText(im, model.names[int(c)], (int(box.xyxy[0][0]), int(box.xyxy[0][1]-10)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
        "      cv2.rectangle(im, (int(box.xyxy[0][0]), int(box.xyxy[0][1])), (int(box.xyxy[0][2]), int(box.xyxy[0][3])), (0, 255, 0), 2)   # draw boxes on img\n",
        "      cv2.imwrite(\"Finresults.jpg\",im)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}